{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习100天——第3天：多元线性回归（Multiple Linear Regression）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第1步：数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**导入库**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**导入数据集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole dataset is: \n",
      "     R&D Spend  Administration  Marketing Spend       State     Profit\n",
      "0   165349.20       136897.80        471784.10    New York  192261.83\n",
      "1   162597.70       151377.59        443898.53  California  191792.06\n",
      "2   153441.51       101145.55        407934.54     Florida  191050.39\n",
      "3   144372.41       118671.85        383199.62    New York  182901.99\n",
      "4   142107.34        91391.77        366168.42     Florida  166187.94\n",
      "5   131876.90        99814.71        362861.36    New York  156991.12\n",
      "6   134615.46       147198.87        127716.82  California  156122.51\n",
      "7   130298.13       145530.06        323876.68     Florida  155752.60\n",
      "8   120542.52       148718.95        311613.29    New York  152211.77\n",
      "9   123334.88       108679.17        304981.62  California  149759.96\n",
      "10  101913.08       110594.11        229160.95     Florida  146121.95\n",
      "11  100671.96        91790.61        249744.55  California  144259.40\n",
      "12   93863.75       127320.38        249839.44     Florida  141585.52\n",
      "13   91992.39       135495.07        252664.93  California  134307.35\n",
      "14  119943.24       156547.42        256512.92     Florida  132602.65\n",
      "15  114523.61       122616.84        261776.23    New York  129917.04\n",
      "16   78013.11       121597.55        264346.06  California  126992.93\n",
      "17   94657.16       145077.58        282574.31    New York  125370.37\n",
      "18   91749.16       114175.79        294919.57     Florida  124266.90\n",
      "19   86419.70       153514.11             0.00    New York  122776.86\n",
      "20   76253.86       113867.30        298664.47  California  118474.03\n",
      "21   78389.47       153773.43        299737.29    New York  111313.02\n",
      "22   73994.56       122782.75        303319.26     Florida  110352.25\n",
      "23   67532.53       105751.03        304768.73     Florida  108733.99\n",
      "24   77044.01        99281.34        140574.81    New York  108552.04\n",
      "25   64664.71       139553.16        137962.62  California  107404.34\n",
      "26   75328.87       144135.98        134050.07     Florida  105733.54\n",
      "27   72107.60       127864.55        353183.81    New York  105008.31\n",
      "28   66051.52       182645.56        118148.20     Florida  103282.38\n",
      "29   65605.48       153032.06        107138.38    New York  101004.64\n",
      "30   61994.48       115641.28         91131.24     Florida   99937.59\n",
      "31   61136.38       152701.92         88218.23    New York   97483.56\n",
      "32   63408.86       129219.61         46085.25  California   97427.84\n",
      "33   55493.95       103057.49        214634.81     Florida   96778.92\n",
      "34   46426.07       157693.92        210797.67  California   96712.80\n",
      "35   46014.02        85047.44        205517.64    New York   96479.51\n",
      "36   28663.76       127056.21        201126.82     Florida   90708.19\n",
      "37   44069.95        51283.14        197029.42  California   89949.14\n",
      "38   20229.59        65947.93        185265.10    New York   81229.06\n",
      "39   38558.51        82982.09        174999.30  California   81005.76\n",
      "40   28754.33       118546.05        172795.67  California   78239.91\n",
      "41   27892.92        84710.77        164470.71     Florida   77798.83\n",
      "42   23640.93        96189.63        148001.11  California   71498.49\n",
      "43   15505.73       127382.30         35534.17    New York   69758.98\n",
      "44   22177.74       154806.14         28334.72  California   65200.33\n",
      "45    1000.23       124153.04          1903.93    New York   64926.08\n",
      "46    1315.46       115816.21        297114.46     Florida   49490.75\n",
      "47       0.00       135426.92             0.00  California   42559.73\n",
      "48     542.05        51743.15             0.00    New York   35673.41\n",
      "49       0.00       116983.80         45173.06  California   14681.40\n",
      "X is: \n",
      " [[165349.2 136897.8 471784.1 'New York']\n",
      " [162597.7 151377.59 443898.53 'California']\n",
      " [153441.51 101145.55 407934.54 'Florida']\n",
      " [144372.41 118671.85 383199.62 'New York']\n",
      " [142107.34 91391.77 366168.42 'Florida']\n",
      " [131876.9 99814.71 362861.36 'New York']\n",
      " [134615.46 147198.87 127716.82 'California']\n",
      " [130298.13 145530.06 323876.68 'Florida']\n",
      " [120542.52 148718.95 311613.29 'New York']\n",
      " [123334.88 108679.17 304981.62 'California']]\n",
      "Y is: \n",
      " [192261.83 191792.06 191050.39 182901.99 166187.94 156991.12 156122.51\n",
      " 155752.6  152211.77 149759.96 146121.95 144259.4  141585.52 134307.35\n",
      " 132602.65 129917.04 126992.93 125370.37 124266.9  122776.86 118474.03\n",
      " 111313.02 110352.25 108733.99 108552.04 107404.34 105733.54 105008.31\n",
      " 103282.38 101004.64  99937.59  97483.56  97427.84  96778.92  96712.8\n",
      "  96479.51  90708.19  89949.14  81229.06  81005.76  78239.91  77798.83\n",
      "  71498.49  69758.98  65200.33  64926.08  49490.75  42559.73  35673.41\n",
      "  14681.4 ]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('../datasets/50_Startups.csv')\n",
    "X = dataset.iloc[ : , :-1].values\n",
    "Y = dataset.iloc[ : ,  4 ].values\n",
    "print(\"Whole dataset is: \\n\", dataset)\n",
    "print(\"X is: \\n\", X[:10])\n",
    "print(\"Y is: \\n\", Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**将类别数据数字化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labelencoder: \n",
      " [[165349.2 136897.8 471784.1 2]\n",
      " [162597.7 151377.59 443898.53 0]\n",
      " [153441.51 101145.55 407934.54 1]\n",
      " [144372.41 118671.85 383199.62 2]\n",
      " [142107.34 91391.77 366168.42 1]\n",
      " [131876.9 99814.71 362861.36 2]\n",
      " [134615.46 147198.87 127716.82 0]\n",
      " [130298.13 145530.06 323876.68 1]\n",
      " [120542.52 148718.95 311613.29 2]\n",
      " [123334.88 108679.17 304981.62 0]]\n",
      "onehot: \n",
      " [[0.0000000e+00 0.0000000e+00 1.0000000e+00 1.6534920e+05 1.3689780e+05\n",
      "  4.7178410e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.6259770e+05 1.5137759e+05\n",
      "  4.4389853e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5344151e+05 1.0114555e+05\n",
      "  4.0793454e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 1.4437241e+05 1.1867185e+05\n",
      "  3.8319962e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4210734e+05 9.1391770e+04\n",
      "  3.6616842e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 1.3187690e+05 9.9814710e+04\n",
      "  3.6286136e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3461546e+05 1.4719887e+05\n",
      "  1.2771682e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3029813e+05 1.4553006e+05\n",
      "  3.2387668e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 1.2054252e+05 1.4871895e+05\n",
      "  3.1161329e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.2333488e+05 1.0867917e+05\n",
      "  3.0498162e+05]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.7/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib64/python3.7/site-packages/sklearn/preprocessing/_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "X[: , 3] = labelencoder.fit_transform(X[ : , 3])\n",
    "print(\"labelencoder: \\n\", X[:10])\n",
    "\n",
    "onehotencoder = OneHotEncoder(categorical_features = [3])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "print(\"onehot: \\n\", X[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**躲避虚拟变量陷阱**\n",
    "\n",
    "在回归预测中我们需要所有的数据都是numeric的，但是会有一些非numeric的数据，比如国家，省，部门，性别。这时候我们需要设置虚拟变量（Dummy variable）。做法是将此变量中的每一个值，衍生成为新的变量，是设为1，否设为0.举个例子，“性别”这个变量,我们可以虚拟出“男”和”女”两虚拟变量，男性的话“男”值为1，”女”值为0；女性的话“男”值为0，”女”值为1。\n",
    "\n",
    "但是要注意，这时候虚拟变量陷阱就出现了。就拿性别来说，其实一个虚拟变量就够了，比如 1 的时候是“男”， 0 的时候是”非男”，即为女。如果设置两个虚拟变量“男”和“女”，语义上来说没有问题，可以理解，但是在回归预测中会多出一个变量，多出的这个变量将会对回归预测结果产生影响。一般来说，如果虚拟变量要比实际变量的种类少一个。 \n",
    "\n",
    "在多重线性回归中，变量不是越多越好，而是选择适合的变量。这样才会对结果准确预测。如果category类的特征都放进去，拟合的时候，所有权重的计算，都可以有两种方法实现，一种是提高某个category的w，一种是降低其他category的w，这两种效果是等效的，也就是发生了共线性,虚拟变量系数相加和为1，出现完全共线陷阱。\n",
    "\n",
    "**但是下面测试尽然和想法不一致。。。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X[: , 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**拆分数据集为训练集和测试集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test is: \n",
      " [[0.0000000e+00 1.0000000e+00 0.0000000e+00 6.6051520e+04 1.8264556e+05\n",
      "  1.1814820e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.0067196e+05 9.1790610e+04\n",
      "  2.4974455e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0191308e+05 1.1059411e+05\n",
      "  2.2916095e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.7892920e+04 8.4710770e+04\n",
      "  1.6447071e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5344151e+05 1.0114555e+05\n",
      "  4.0793454e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 7.2107600e+04 1.2786455e+05\n",
      "  3.5318381e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 2.0229590e+04 6.5947930e+04\n",
      "  1.8526510e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 6.1136380e+04 1.5270192e+05\n",
      "  8.8218230e+04]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.3994560e+04 1.2278275e+05\n",
      "  3.0331926e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4210734e+05 9.1391770e+04\n",
      "  3.6616842e+05]]\n",
      "Y_test is: \n",
      " [103282.38 144259.4  146121.95  77798.83 191050.39 105008.31  81229.06\n",
      "  97483.56 110352.25 166187.94]\n",
      "X1_test is: \n",
      " [[1.0000000e+00 0.0000000e+00 6.6051520e+04 1.8264556e+05 1.1814820e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0067196e+05 9.1790610e+04 2.4974455e+05]\n",
      " [1.0000000e+00 0.0000000e+00 1.0191308e+05 1.1059411e+05 2.2916095e+05]\n",
      " [1.0000000e+00 0.0000000e+00 2.7892920e+04 8.4710770e+04 1.6447071e+05]\n",
      " [1.0000000e+00 0.0000000e+00 1.5344151e+05 1.0114555e+05 4.0793454e+05]\n",
      " [0.0000000e+00 1.0000000e+00 7.2107600e+04 1.2786455e+05 3.5318381e+05]\n",
      " [0.0000000e+00 1.0000000e+00 2.0229590e+04 6.5947930e+04 1.8526510e+05]\n",
      " [0.0000000e+00 1.0000000e+00 6.1136380e+04 1.5270192e+05 8.8218230e+04]\n",
      " [1.0000000e+00 0.0000000e+00 7.3994560e+04 1.2278275e+05 3.0331926e+05]\n",
      " [1.0000000e+00 0.0000000e+00 1.4210734e+05 9.1391770e+04 3.6616842e+05]]\n",
      "Y1_test is: \n",
      " [103282.38 144259.4  146121.95  77798.83 191050.39 105008.31  81229.06\n",
      "  97483.56 110352.25 166187.94]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(X1, Y, test_size = 0.2, random_state = 0)\n",
    "print(\"X_test is: \\n\", X_test)\n",
    "print(\"Y_test is: \\n\", Y_test)\n",
    "print(\"X1_test is: \\n\", X1_test)\n",
    "print(\"Y1_test is: \\n\", Y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第2步：在训练集上训练多元线性回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, Y_train)\n",
    "regressor1 = LinearRegression()\n",
    "regressor1.fit(X1_train, Y1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第3步：在测试集上预测结果¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred is \n",
      " [103015.20159795 132582.27760816 132447.73845175  71976.09851258\n",
      " 178537.48221057 116161.24230167  67851.69209676  98791.73374687\n",
      " 113969.43533014 167921.06569552]\n",
      "y1_pred is \n",
      " [103015.20159796 132582.27760816 132447.73845175  71976.09851259\n",
      " 178537.48221054 116161.24230163  67851.69209676  98791.73374688\n",
      " 113969.43533012 167921.0656955 ]\n"
     ]
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "y1_pred = regressor1.predict(X1_test)\n",
    "print(\"y_pred is \\n\", y_pred)\n",
    "print(\"y1_pred is \\n\", y1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
